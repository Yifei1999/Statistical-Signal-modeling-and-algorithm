# written by Liu Yifei, Nov 16, 2021
# exp4, course: statistic signal analysis and modeling
# this program is the appliance of Kmeans Algorithm
# start clustering by using initial point generated by random function
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D


class KmeansCluster:
    def __init__(self):
        # M_AttrNum: the number of attributes in a sample, in this exp is 3
        # Epoch: the times of iteration in Kmeans
        # DataSet: list - list - 3 array, the current cluster result,
        #          for example [ [np.array([1,2,3]) ], [np.array([2,2,3]),np.array([3,2,3]) ] ]  has 2 cluster and 3 data sample
        # ClusterCentral: list - 3 array, the current cluster center
        # ClusterNum: the number of cluster
        # DataNum: the number of samples in dataset
        self.M_AttrNum = 3  # is M
        self.Epoch = 0
        self.Dataset  = None         # list * list * array    init: [[[data1] [data2] ]]   类型转换  涉及算数用矩阵，涉及合并用列表
        self.ClusterCentral  = []  # list * array[]
        self.ClusterNum = None
        self.DataNum = 0

    def Initalise(self,dataset,clusternum,epoch):
        # the inital function of model, loading samples and set start point
        # starting by arranging all samples in 1 cluster
        self.Dataset = [dataset]
        for j in range(clusternum-1):
            self.Dataset.append([])

        self.DataNum = len(dataset)
        self.ClusterNum = clusternum
        self.Epoch = epoch

        for i in range(self.ClusterNum):
            # set random start point
            self.ClusterCentral = self.ClusterCentral + [np.random.rand(3)*3 - 3/2 + np.array(np.array(dataset).mean(axis=0))]

    def DisMetic(self,pointa,pointb):
        # calculate E-DISTANCE between array A and B
        # parameters:
        # - pointa, pointb: both are 3 np.array
        return ((pointa - pointb) * (pointa - pointb)).sum()

    def CentalCal(self,dataset):
        # calculate the mass center
        # parameter:
        # - dataset: list - 3 array, the list of samples, example: [ np.array([1,2,3]), np.array([2,2,3]) ]
        CentralPoint = np.array([0,0,0])
        for i, v in enumerate(dataset):
            CentralPoint = CentralPoint + dataset[i]
        return CentralPoint / len(dataset)

    def GetMinDisCentral(self,point):    # 3 array     return:  int
        # get the closest cluster center
        # parameter:
        # - point: 3 array
        MinPointIndex = 0
        MinDis = self.DisMetic(point,self.ClusterCentral[0])
        # select a min distance and center
        for i in range(1,self.ClusterNum):
            if self.DisMetic(point,self.ClusterCentral[i]) < MinDis:
                MinDis = self.DisMetic(point,self.ClusterCentral[i])
                MinPointIndex = i
        # return a int index of the cluster center, self.ClusterCentral[MinPointIndex] is the central point
        return MinPointIndex

    def SingleIter(self):
        # doing the iteration process once
        # stage1: classify the samples in new sets
        TempDataset = []
        for i in range(self.ClusterNum):
            TempDataset.append([])
        for i, v in enumerate(self.Dataset):
            for j, w in enumerate(v):
                MinPointIndex = self.GetMinDisCentral(w)
                TempDataset[MinPointIndex].append(w)
        self.Dataset = TempDataset

        # stage2: update the center mass point
        for i in range(self.ClusterNum):
            if len(self.Dataset[i]) == 0:
                self.ClusterCentral[i] = self.ClusterCentral[i-1] + np.random.rand(3)*2 - 1
            else:
                self.ClusterCentral[i] = self.CentalCal(self.Dataset[i])

    def TrainModel(self):
        # manipulate the process several times
        for i in range(self.Epoch):
            self.SingleIter()

    def EstimateMeans(self):
        # return a list - 3 array, the estimation of center points
        return self.ClusterCentral

    def EstimateCov(self):  # list * (n*n array)
        Covar = []
        for i in range(self.ClusterNum):
            Covar = Covar + [np.cov(self.Dataset[i], rowvar=False)]
        # return a list - n*n array, the estimation of covariance matrix
        return Covar

    def EstimatePro(self):
        Pro = []
        for i in range(self.ClusterNum):
            Pro = Pro + [len(self.Dataset[i])/self.DataNum]
        # return a list
        return Pro

if __name__ == '__main__':
    # number of clusters and iteration epoch
    ClusterNum = 2
    Epoch = 3

    # load the Train Set
    fp_trainset = open('./Train.txt', 'r')
    attrSet = []
    classSet = []
    for line in fp_trainset:
        ls = line.strip('\n').replace('(', ' ').replace(')', ' ').replace(':', ' ').split()
        ls_data = [ls[0]] + list(map(float, ls[1:4:1]))
        classSet.append(ls_data[0])
        attrSet.append(np.array(ls_data[1:4:1]))
    fp_trainset.close()
    print('loading trainset samples:', len(attrSet))

    # loading samples of class A in dataset
    DataSetA = []
    for i, v in enumerate(classSet):
        if v == 'A':
            DataSetA.append(attrSet[i])
    print('target set A:', len(DataSetA))

    # train the model using class A
    K = KmeansCluster()
    K.Initalise(DataSetA,ClusterNum,Epoch)
    K.TrainModel()

    # display the result
    fig = plt.figure()
    ax = Axes3D(fig)
    for i in range(K.ClusterNum):
        Colorset = ['r', 'b', 'g', 'y', 'k', 'c', 'm', 'w']
        x = np.array(K.Dataset[i])[:,0]
        y = np.array(K.Dataset[i])[:,1]
        z = np.array(K.Dataset[i])[:,2]
        ax.scatter(x, y, z, c=Colorset[i],s=10)
    plt.xlabel('X')
    plt.ylabel('Y')
    plt.show()

